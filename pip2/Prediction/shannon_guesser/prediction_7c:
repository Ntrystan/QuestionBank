.. activecode:: prediction_7c:
    :author: Brad Miller
    :difficulty: 3
    :basecourse: pip2
    :topic: Prediction/shannon_guesser
    :from_source: None
    :include: prediction_7a

    import math
    def entropy(txt, rls):
        guess_frequencies = {}
        prev_txt = ""
        for c in txt:
            to_try = guesser(prev_txt, rls)
            guess_count = to_try.index(c) + 1
            if guess_count in guess_frequencies:
                guess_frequencies[guess_count] += 1
            else:
                guess_frequencies[guess_count] = 1
            prev_txt += c

        print "guess_frequencies:", guess_frequencies
        # from frequencies, compute entropy
        acc = 0.0
        for i in range(len(guess_frequencies.keys())):
            guess_count = guess_frequencies.keys()[i]
            probability = guess_frequencies[guess_count] / float(len(txt))
            if i < len(guess_frequencies.keys()) - 1:
                next_guess_count = guess_frequencies.keys()[i+1]
                next_probability = guess_frequencies[next_guess_count] / float(len(txt))
            else:
                next_probability = 0
            acc += guess_count * (probability-next_probability) * math.log(guess_count, 2)

        print "entropy:", acc
        return acc


    entropy(test_txt, [(None, alphabet)])